apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-inference-config
  namespace: default
  labels:
    app: ai-inference-platform
data:
  # Redis Configuration
  # Format: redis://<service-name>:<port>/<database>
  # In Kubernetes, services are accessible by name
  redis_url: "redis://ai-inference-redis:6379/0"
  
  # Environment
  environment: "production"
  
  # Logging
  log_level: "INFO"
  
  # Rate Limiting
  rate_limit_enabled: "true"
  rate_limit_per_minute: "10"
  
  # OpenTelemetry
  otel_enabled: "true"
  # otel_exporter_otlp_endpoint: "http://otel-collector:4317"
  
  # Model Configuration
  model_name: "default-model"
  model_version: "1.0.0"
  model_max_tokens: "1000"
  model_temperature: "0.7"
  
  # Service Configuration
  service_name: "ai-inference-platform"
  service_version: "1.0.0"

